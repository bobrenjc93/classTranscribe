[{"text":" it might be easier to look at the iterative version because we already sort of analyzed it right? nothing there is really different, all we've done is replace a queue with a stack, so as long as we can do the stack operation in constant time, like we could for the queue, which we know we can, then nothing there really changes.","width":1024},{"text":"so you sort of should know that the analysis is not going to be any different","width":256},{"text":"if we look at the recursive version, then ok, the stack stuff isn't quite as explicit. now its with function calls, so now we have to think a little bit about how many times is this function called and how much work is each function call doing, but it ends up being the same analysis","width":1152},{"text":"so how many times would this dfs recursive function be called?","width":384},{"text":"so overall, the whole entire search, how many times?","width":576},{"text":"N, once per vertex, i only call it if that vertex is unexplored, so every time i see a vertex for the very first time is when i call this dfs function","width":704},{"text":"so this whole thing is going to be invoked O(n) times and then the question is how much work does it do at every invokation?","width":512},{"text":"setting the vertex state, looking at vertex states, looking at edge states, all that is sort of constant times, because thats just look into the vertex or into the edge, or into a hash table, ok thats fine, none of that's going to matter, the only graph function that im calling here that depends on the implementation of the graph is g.adjacent(u)","width":1664},{"text":"which again we know for the matrix is O(n) where as the list gives us O(deg(u))","width":1280},{"text":"and ok thats really the only difference","width":384},{"text":"so i have something thats being invoked for every vertex, and the amount of work im doing.. the same argument that sort of applies for the amount of working im doing for every edge, im looping over the outgoing, im looping over the adjacent verticies of the vertex u, so im looking at all of its outgoing edges and im doing some amount of constant work, im looking at that edge to set it, so im doing work proportional to the degree of that vertex","width":1856},{"text":"so i still have sum of all u in v, of deg(u)","width":640},{"text":"k times that for dealing with the edge setting","width":320},{"text":"plus again i need to start off the loop for every vertex, that was..","width":832},{"text":"for every vertex i call the adjacent of u function, so however long that takes, its the sum over all the vertices of that","width":512},{"text":"were going to assume that the function calls themselves, like calling a function is constant time, like, make a stack frame and go into that function, we've always assumed that is constant time, so we can ignore that part","width":1216},{"text":"so essentially this is it","width":256},{"text":"we have, every vertex gets the cost of the adjacent of that vertex, sets that vertex label exactly once and then does stuff with the edges right.","width":640},{"text":"i can ignore the setting of the vertex, the current vertex's label because we know that getting the adjacent vertices of a vertex is going to be worse than constant time and setting the label is going to be constant time","width":896},{"text":"if you wanted to get padantic its also a sum of u in v of O(1)","width":384},{"text":"setting the vertex label for every vertex, but we know that this part is going to overshadow it","width":384},{"text":"well except for the case where a graph has no edges, i guess this is sort of important","width":960},{"text":"in the case where your graph has no edges, getting the adjacent vertices is constant time right","width":384},{"text":"so we need that, so then we know that, again we going to have the same sort of set up where this is O(N), thats just k times the sum of the deg() of all the vertices which is twice the number of edges, so thats 2km","width":704},{"text":"O() of that is just M","width":192},{"text":"this thing is going to be the thing that differs, so for the matix again its going to end up being, the cost of adjacent function is O(n) i call that N times, so thats O(N^2)","width":960},{"text":"but for the adj lists, that costs deg(v) and thats the sum of deg(v) which is twice the nubmer of edges, so this is O(m)","width":640},{"text":"and then finally we have this thing were we know were atleast labeling every vertex once","width":448},{"text":"so we have a constant amount of work for every vertex","width":128},{"text":"","width":64},{"text":"which is O(n)","width":192},{"text":"every vertex is labeled once, every vertex is checked","width":384},{"text":"once for all the edges so tahts where you know, this stuff is coming from ","width":448},{"text":"thats setting the edges and looking at the vertices thats done once, sort of twice per edge","width":320},{"text":"this whole thing comes out to, for the adjacency matrix as being O(m) + O(n^2) + O(n) which is what?","width":512},{"text":"O(n^2)","width":192},{"text":"so that ok, that worked out as we expected and the other one is O(m) + O(m) + O(n)","width":384},{"text":"which is just O(n+m)","width":384},{"text":"then the case of an adjacency list, we have the best traversal running time that we could again","width":1152},{"text":"and the case is the same for an adjacency matrix, its still O(n^2)","width":256},{"text":"but if you're using an adjacency matrix you're graph is probably dense anyway so its probably not that bad","width":320},{"text":"the moral of the story again is dont use adjacency matrices for sparse graphs","width":320},{"text":"the very last thing i want to do, i want to start to cover this atleast, in the interest of time, no we're going to talk, so the two algorithms that we just finished, bfs and dfs, gave us spanning trees on those discovery edges, so we could use those to get to arbitray tree","width":1536},{"text":"however, now i've put a bunch of edge weights in the graph","width":256},{"text":"now im saying that edges have an inherent cost associated with them. this is a natural things to do, it might be the latency of a network link, it might be the cost of driving from hub a to hub b, it might be amount of fuel you use to fly from city a to city b, so its natural in graph to assign edge weights","width":1664},{"text":"its the travel time or whatever","width":192},{"text":"and then, if you, if you are doing that and you just run a regular bfs or dfs its just going to give you some arbitrary spanning tree, it doesn't care at all about what the edge weights are","width":576},{"text":"but a natrual question would be, can i get the best spanning tree, can i get the spanning tree that has the minimum total edge weights","width":640}]